{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core.dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core.dashboards\n",
    "> Supplies dashboards and dashboard components. Dashboards are defined as classes, to show the dashboard use the .show() function on an dashboard instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import List, Union, Optional\n",
    "from abc import ABC, abstractmethod\n",
    "from math import floor, ceil\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import panel.widgets as pnw\n",
    "\n",
    "from icevision_dashboards.plotting import *\n",
    "from icevision_dashboards.core.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Dashboard(ABC):\n",
    "    def __init__(self, width: int = 500, height: int = 500):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.build_gui()\n",
    "        \n",
    "    @abstractmethod\n",
    "    def show(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def build_gui(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstaract base class for dashboards. Inherited classes are required to implement a `build_gui` function, that builds the gui to be shown as well as setting up interactions and a `show` function that returns the gui. The `build_gui` function is called at the end of the `__init__` function. Most dashboards require different descriptors from the dataset (data, stats usw.). For simple handling of cases where the name is different (a vision dataset might have stats for the images, the annotations and the annotation classes) most dashboards have class variables for the different descriptors, wich can be changed to use a new descriptor.\n",
    "\n",
    "For complexer dashboards, that use other dashboards as components the same approche is used, where class varibales ar used to choose a implementation of a dashboard. With this, in some cases only certain parts need to be replaced and not everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "class TestDataset(GenericDataset):\n",
    "    def __init__(self, data=None, name=\"TestDataset\", description=\"A dataset for testing\"):\n",
    "        if data is None:\n",
    "            data = pd.DataFrame(\n",
    "                {\n",
    "                    \"objects_per_image\": [3,2,3,3,2,3,3,1,3],\n",
    "                    \"filepath\": [\"a\", \"b\", \"a\", \"a\", \"b\", \"c\", \"c\", \"d\", \"c\"],\n",
    "                    \"label\": [\"Dog\",\"Dog\",\"Cat\",\"Dog\",\"Cat\",\"Bird\",\"Dog\",\"Cat\",\"Bird\"]\n",
    "                }\n",
    "            )\n",
    "        super().__init__(data, name=name, description=description)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    # use properties as quick replacement for descriptors\n",
    "    @property\n",
    "    def data(self):\n",
    "        return self.base_data\n",
    "    \n",
    "    @property\n",
    "    def stats(self):\n",
    "        return pd.DataFrame({\"num_datapoints\": [self.base_data.shape[0]]})\n",
    "    \n",
    "    @property\n",
    "    def stats_dataset(self):\n",
    "        return pd.DataFrame({\"num_datapoints\": [self.base_data.shape[0]]})\n",
    "    \n",
    "    @property\n",
    "    def stats_images(self):\n",
    "        return self.data\n",
    "    \n",
    "    @property\n",
    "    def stats_classes(self):\n",
    "        return pd.DataFrame({\"num_datapoints\": [self.base_data.shape[0]]})\n",
    "    \n",
    "    def save(self, export_path):\n",
    "        print(\"Saved data at \" + export_path)\n",
    "    \n",
    "    @classmethod\n",
    "    def create_new_from_mask(cls, instance, mask):\n",
    "        new_df = instance.data[mask]\n",
    "        return cls(new_df, instance.name+\"_new\", instance.description+\"_new\")\n",
    "    \n",
    "test_dataset = TestDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Gallery(Dashboard, ABC):\n",
    "    def __init__(self, dataset, sort_cols=None, sort_desciptor=None, width=500, height=500):\n",
    "        if sort_cols is None and sort_desciptor is not None or sort_cols is not None and sort_desciptor is None:\n",
    "            raise ValueError(\"sort_cols and sort_descrptor need to be both none or both need to be set.\")\n",
    "        else:\n",
    "            self.sort_cols = sort_cols\n",
    "            self.sort_desciptor = sort_desciptor\n",
    "        self.index_mapping = [i for i in range(len(dataset))]\n",
    "        self.dataset = dataset\n",
    "        super().__init__(width, height)\n",
    "        \n",
    "    def get_mapped_index(self, idx):\n",
    "        return self.index_mapping[idx]\n",
    "        \n",
    "    @abstractmethod\n",
    "    def load_image_by_index(self, index, width, height):\n",
    "        # needs to be a bokeh figure of pn Row, Column etc.\n",
    "        pass\n",
    "        \n",
    "    def update_sorting(self, event):\n",
    "        self.index_mapping = getattr(self.dataset, self.sort_desciptor)[event.obj.value].argsort()\n",
    "        \n",
    "    def build_gui(self):\n",
    "        if self.sort_cols is not None:\n",
    "            self.sorter = pnw.Select(name=\"Sort by\", options=self.sort_cols)\n",
    "            self.sorter.param.watch(self.update_sorting, \"value\")\n",
    "        \n",
    "        self.btn_prev = pnw.Button(name=\"<\", width=int(2*self.width/6))\n",
    "        self.btn_next = pnw.Button(name=\">\", width=int(2*self.width/6))\n",
    "        self.current = pnw.TextInput(value=\"1\", width=int(self.width/6))\n",
    "        self.image_count = pn.Row(\"/\" + str(len(self.dataset)), width=int(self.width/6))\n",
    "        if self.sort_cols is not None:\n",
    "            self.gui_controlls = pn.Column(self.sorter, pn.Row(self.btn_prev, self.current, self.image_count, self.btn_next, align=\"center\", height=50))\n",
    "        else:\n",
    "            self.gui_controlls = pn.Row(self.btn_prev, self.current, self.image_count, self.btn_next, align=\"center\", height=50)\n",
    "        self._image = pn.Row(self.load_image_by_index(int(self.current.value)-1), align=\"center\")\n",
    "        self.gui = pn.Column(self.gui_controlls, self.image)\n",
    "        \n",
    "        self.btn_prev.on_click(self._previous)\n",
    "        self.btn_next.on_click(self._next)\n",
    "        \n",
    "    @property\n",
    "    def image(self):\n",
    "        return self._image\n",
    "    \n",
    "    @image.setter\n",
    "    def image(self, image):\n",
    "        self._image = image\n",
    "        self.gui[1] = self._image\n",
    "        \n",
    "    def _next(self, _):\n",
    "        index = int(self.current.value)\n",
    "        if index == len(self.dataset):\n",
    "            index = 1\n",
    "        else:\n",
    "            index += 1\n",
    "        self.current.value = str(index)\n",
    "        self.image = pn.Row(self.load_image_by_index(index-1), align=\"center\")\n",
    "        \n",
    "    def _previous(self, _):\n",
    "        index = int(self.current.value)\n",
    "        if index == 1:\n",
    "            index = len(self.dataset)\n",
    "        else:\n",
    "            index -= 1\n",
    "        self.current.value = str(index)\n",
    "        self.image = pn.Row(self.load_image_by_index(index-1), align=\"center\")\n",
    "    \n",
    "    def show(self):\n",
    "        return self.gui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a gallery with the images of a dataset. The dataset is required to have the following `method`:\n",
    "\n",
    "- `load_image_by_index`: Takes an index and returns a bokeh figure or panel widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGallery(Gallery):\n",
    "    def load_image_by_index(self, index: int):\n",
    "        index = self.get_mapped_index(index)\n",
    "        return pn.Row(str(self.dataset.data[\"objects_per_image\"][index]) + \" - \" + str(self.dataset.data[\"label\"][index]))\n",
    "\n",
    "test_gallery = TestGallery(test_dataset, sort_cols=[\"label\", \"objects_per_image\"], sort_desciptor=\"stats_images\").show()\n",
    "assert test_gallery[1][0][0].object == \"3 - Dog\"\n",
    "test_gallery[0][1][0].clicks += 1\n",
    "test_gallery[0][1][0].clicks += 1\n",
    "assert test_gallery[1][0][0].object == \"1 - Cat\"\n",
    "test_gallery[0][1][-1].clicks += 1\n",
    "test_gallery[0][1][-1].clicks += 1\n",
    "assert test_gallery[1][0][0].object == \"3 - Dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DatasetOverview(Dashboard):\n",
    "    DESCRIPTOR_DATA = \"data\"\n",
    "    DESCRIPTOR_STATS = \"stats\"\n",
    "    \n",
    "    def __init__(self, dataset: GenericDataset, height: int = 500, width: int = 500):\n",
    "        \"\"\"Creates an overview of a dataset\"\"\"\n",
    "        self.dataset = dataset\n",
    "        super().__init__(height=height, width=width)\n",
    "        \n",
    "    def _generate_dataset_tab(self):\n",
    "        overview_table = table_from_dataframe(getattr(self.dataset, self.DESCRIPTOR_DATA), width=self.width, height=self.height)\n",
    "        return overview_table\n",
    "        \n",
    "    def _generate_datset_stats_tab(self):\n",
    "        overview_table = table_from_dataframe(getattr(self.dataset, self.DESCRIPTOR_STATS), width=self.width, height=self.height)\n",
    "        return overview_table\n",
    "    \n",
    "    def build_gui(self):\n",
    "        dataset_tab = self._generate_dataset_tab()\n",
    "        dataset_stats_tab = self._generate_datset_stats_tab()\n",
    "        self.gui = pn.Tabs((\"Dataset overview\", dataset_tab), (\"Dataset stats overview\", dataset_stats_tab), align=\"start\")\n",
    "        \n",
    "    def show(self):\n",
    "        return self.gui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is required to have to following (default) `descriptors`:\n",
    "\n",
    "- **data** [pd.Dataframe]: Each row should be a singel datapoint/annotation\n",
    "- **stats** [pd.Datagrame]: One row that describes the dataset, were the columns represent different information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_overview = DatasetOverview(test_dataset, height=200)\n",
    "test_dataset_overview.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiDatasetOverview(Dashboard):\n",
    "    DESCRIPTOR_DATA = \"stats\"\n",
    "    \n",
    "    def __init__(self, datasets: Union[List[GenericDataset], ObservableList], height=100, width=1000, with_del_button=False):\n",
    "        self.datasets = datasets if isinstance(datasets, ObservableList) else ObservableList(datasets)\n",
    "        self.datasets.register_callback(self.update_table)\n",
    "        self.with_del_button = with_del_button\n",
    "        super().__init__(width=width, height=height)\n",
    "    \n",
    "    def create_overview_df(self):\n",
    "        return pd.concat([getattr(dataset, self.DESCRIPTOR_DATA) for dataset in self.datasets]) if len(self.datasets) > 0 else pd.DataFrame() \n",
    "    \n",
    "    def build_gui(self):\n",
    "        self.delete_button = pnw.Button(name=\"Delete\", width=self.width, height=25)\n",
    "        self.overview_table = table_from_dataframe(self.create_overview_df(), height=self.height-25)\n",
    "        if self.with_del_button:\n",
    "            self.delete_button.on_click(self.delete_entry)\n",
    "            self.gui = pn.Column(self.delete_button, self.overview_table)\n",
    "        else:\n",
    "            self.gui = pn.Column(self.overview_table)\n",
    "        \n",
    "    def delete_entry(self, clicks):\n",
    "        selection = self.overview_table.selection\n",
    "        self.datasets.list = [dataset for index, dataset in enumerate(self.datasets) if index not in selection]\n",
    "    \n",
    "    def update_table(self, event):\n",
    "        self.overview_table.value = self.create_overview_df()\n",
    "        self.overview_table.height = height=self.height-25\n",
    "    \n",
    "    def show(self):\n",
    "        return self.gui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is required to have to following `descriptors`:\n",
    "\n",
    "- **stats** [pd.Datagrame]: One row that descripbes the dataset, were the columns represent different information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_multi_dataset_overview = MultiDatasetOverview([test_dataset, test_dataset], with_del_button=True)\n",
    "test_multi_dataset_overview.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DatasetComparison(Dashboard):\n",
    "    DESCRIPTOR_DATA = \"data\"\n",
    "    DESCRIPTOR_STATS = \"stats\"\n",
    "    \n",
    "    def _get_descriptor_for_all_datasets(self, descriptor_name):\n",
    "        return [getattr(dataset, descriptor_name) for dataset in self.datasets]\n",
    "    \n",
    "    def __init__(self, datasets: List[GenericDataset], height: int = 500, width: int = 500):\n",
    "        \"\"\"Creates an overview of a dataset\"\"\"\n",
    "        self.datasets = datasets\n",
    "        super().__init__(height=height, width=width)\n",
    "        \n",
    "    def _generate_dataset_tab(self):\n",
    "        overview_table = table_from_dataframe(self._get_descriptor_for_all_datasets(self.DESCRIPTOR_DATA), width=self.width, height=self.height)\n",
    "        return pn.Column(*overview_table)\n",
    "        \n",
    "    def _generate_datset_stats_tab(self):\n",
    "        overview_table = table_from_dataframe(self._get_descriptor_for_all_datasets(self.DESCRIPTOR_STATS), width=self.width, height=self.height)\n",
    "        return pn.Column(*overview_table)\n",
    "    \n",
    "    def build_gui(self):\n",
    "        dataset_tab = self._generate_dataset_tab()\n",
    "        dataset_stats_tab = self._generate_datset_stats_tab()\n",
    "        self.gui = pn.Tabs((\"Dataset overview\", dataset_tab), (\"Dataset stats overview\", dataset_stats_tab), align=\"start\")\n",
    "        \n",
    "    def show(self):\n",
    "        return self.gui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is required to have to following (default) `descriptors`:\n",
    "\n",
    "- **data** [pd.Dataframe]: Each row should be a singel datapoint/annotation\n",
    "- **stats** [pd.Datagrame]: One row that describes the dataset, were the columns represent different information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_overview = DatasetComparison([test_dataset, test_dataset], height=200)\n",
    "test_dataset_overview.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DatasetFilter(Dashboard, ABC):\n",
    "    DESCRIPTOR_DATA = \"data\"\n",
    "    \n",
    "    def __init__(self, dataset: GenericDataset, columns: Optional[List[str]] = None, height: int = 500, width: int = 500, filter_width: Optional[int] = None, filter_height: Optional[int] = None, n_cols: int = None):\n",
    "        self.dataset = dataset\n",
    "        self.columns = columns if columns is not None else getattr(self.dataset, self.DESCRIPTOR_DATA).columns\n",
    "        self.n_cols = n_cols if n_cols is not None else ceil(len(self.columns)**0.5)\n",
    "        self.n_rows = (len(self.columns)//self.n_cols) + min(1, len(self.columns)%self.n_cols)\n",
    "        self.filter_height = int(height/self.n_rows) if filter_height is None else filter_height\n",
    "        self.filter_width = int(width/self.n_cols) if filter_width is None else filter_width\n",
    "        self.filters = []\n",
    "        self.UPDATING = False\n",
    "        super().__init__(height=height, width=width)\n",
    "    \n",
    "    def build_gui(self):\n",
    "        \"\"\"All filters used below need to have two functions get_selection and update_with_mask.\"\"\"\n",
    "        data_selection = getattr(self.dataset, self.DESCRIPTOR_DATA)[self.columns]\n",
    "        self.generate_filters(data_selection)\n",
    "        # put the images in the grid\n",
    "        self.gui = pn.GridSpec(ncols=self.n_cols, nrows=self.n_rows, width=self.width, height=self.height)\n",
    "        for index, gui_filter in enumerate(self.filters):\n",
    "            self.gui[index//self.n_cols, index%self.n_cols] = gui_filter.show()\n",
    "        # hook all control elements to the update functions\n",
    "        for single_filter in self.filters:\n",
    "            single_filter.register_callback(self.update_plots)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def generate_filters(self, dataselection):\n",
    "        \"\"\"Write handler for the different column types of the datagrame.\"\"\"\n",
    "        pass\n",
    "        \n",
    "    def _update_plots(self, current_selection):\n",
    "        mask = np.array(self.get_selection())\n",
    "        final_mask = np.logical_or(mask, current_selection)\n",
    "        for single_filter in self.filters:\n",
    "            single_filter.update_with_mask(final_mask)\n",
    "        \n",
    "    def update_plots(self, event, old=None, new=None):\n",
    "        if self.UPDATING:\n",
    "            return\n",
    "        else:\n",
    "            self.UPDATING = True\n",
    "            self._update_plots(event)\n",
    "            self.UPDATING = False\n",
    "        \n",
    "    def show(self):\n",
    "        return self.gui\n",
    "    \n",
    "    def get_selection(self):\n",
    "        mask = self.filters[0].get_selection()\n",
    "        for single_filter in self.filters[1:]:\n",
    "            mask = np.logical_and(mask, single_filter.get_selection())\n",
    "        return mask\n",
    "    \n",
    "    def register_callback(self, callback):\n",
    "        \"\"\"Register callback to every underlying filter\"\"\"\n",
    "        for filter in self.filters:\n",
    "            filter.register_callback(callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is required to have to following (default) `descriptors`:\n",
    "\n",
    "- **data** [pd.Dataframe]: Each row should be a singel datapoint/annotation with the columns pepresenting attributes to filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DatasetFilterWithRangeSliderAndMultiSelect(DatasetFilter):\n",
    "    def generate_filters(self, data_selection):\n",
    "        # generate filters\n",
    "        for column in data_selection.columns:\n",
    "            if pd.api.types.is_numeric_dtype(data_selection[column]):\n",
    "                self.filters.append(RangeFilter(data_selection[column].values, column, height=self.filter_height, width=self.filter_width))\n",
    "            elif pd.api.types.is_categorical_dtype(data_selection[column]) or pd.api.types.is_string_dtype(data_selection[column]):\n",
    "                self.filters.append(CategoricalFilter(data_selection[column].values, column, height=self.filter_height, width=self.filter_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_filter = DatasetFilterWithRangeSliderAndMultiSelect(test_dataset, height=350)\n",
    "test_dataset_filter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ScatterDatasetFilter(DatasetFilter):\n",
    "    def __init__(self, dataset: GenericDataset, columns: Optional[List[str]] = None, height: int = 500, width: int = 500, filter_width: Optional[int] = None, filter_height: Optional[int] = None, n_cols: int = None):\n",
    "        super().__init__(dataset, columns, height, width, filter_width, filter_height, n_cols)\n",
    "        self.scatter_filter = None\n",
    "    \n",
    "    def build_gui(self):\n",
    "        \"\"\"All filters used below need to have two functions get_selection and update_with_mask.\"\"\"\n",
    "        data_selection = getattr(self.dataset, self.DESCRIPTOR_DATA)[self.columns]\n",
    "        self.generate_filters(data_selection)\n",
    "        # put the images in the grid\n",
    "        self.categorical_grid = pn.GridSpec(ncols=self.n_cols, nrows=self.n_rows, width=self.width, height=self.height//2)\n",
    "        for index, gui_filter in enumerate(self.filters):\n",
    "            self.categorical_grid[index//self.n_cols, index%self.n_cols] = gui_filter.show()\n",
    "        # hook all control elements to the update functions\n",
    "        for single_filter in self.filters:\n",
    "            single_filter.register_callback(self.update_plots)\n",
    "        # add the scatter filter\n",
    "        self.scatter_filter.register_callback(self.update_plots)\n",
    "        self.gui = pn.Column(self.categorical_grid, self.scatter_filter.show())\n",
    "    \n",
    "    def generate_filters(self, data_selection):\n",
    "        # generate filters\n",
    "        numeric_cols = []\n",
    "        for column in data_selection.columns:\n",
    "            if pd.api.types.is_numeric_dtype(data_selection[column]):\n",
    "                numeric_cols.append(column)\n",
    "            elif pd.api.types.is_categorical_dtype(data_selection[column]) or pd.api.types.is_string_dtype(data_selection[column]):\n",
    "                self.filters.append(CategoricalFilter(data_selection[column].values, column, height=self.filter_height, width=self.filter_width))\n",
    "        # generate generic scatter selector\n",
    "        self.scatter_filter = GenericMulitScatterFilter(data_selection[numeric_cols], height=self.height//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_filter = ScatterDatasetFilter(test_dataset, height=700)\n",
    "test_dataset_filter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DatasetGenerator(Dashboard):\n",
    "    DESCRIPTOR_DATA = \"data\"\n",
    "    DESCRIPTOR_STATS = \"stats\"\n",
    "    \n",
    "    DATASET_FILTER_COLUMNS = None\n",
    "    DATASET_FILTER = DatasetFilterWithRangeSliderAndMultiSelect\n",
    "    MULTI_DATASET_OVERVIEW = MultiDatasetOverview\n",
    "    DATASET_OVERVIEW = DatasetOverview\n",
    "\n",
    "    def __init__(self, dataset, width=500, height=500):\n",
    "        self.base_dataset = dataset\n",
    "        self.created_datasets = ObservableList([])\n",
    "        super().__init__(width, height)\n",
    "        \n",
    "    def build_gui(self):\n",
    "        self.dataset_filter = self.DATASET_FILTER(self.base_dataset, columns=self.DATASET_FILTER_COLUMNS, width=self.width, height=self.height-50)\n",
    "        self.dataset_filter_create_dataset_button = pnw.Button(name=\"Create\", height=50)\n",
    "        self.dataset_filter_create_dataset_button.on_click(self.create_dataset)\n",
    "        self.dataset_filter_with_export = pn.Column(pn.Row(self.dataset_filter.show(), align=\"center\"), pn.Row(self.dataset_filter_create_dataset_button, align=\"center\"))\n",
    "        \n",
    "        self.created_datasets_overview = self.MULTI_DATASET_OVERVIEW(self.created_datasets, with_del_button=True, height=150, width=self.width)\n",
    "        self.selected_dataset_overview = self.DATASET_OVERVIEW(self.base_dataset, height=self.height-250, width=self.width)\n",
    "        self.export_gui = self.create_export_gui()\n",
    "        self.datasets_overview = pn.Column(pn.Row(self.created_datasets_overview.gui, align=\"center\"), pn.Row(self.selected_dataset_overview.gui, align=\"center\"), pn.Row(self.export_gui, align=\"center\"))\n",
    "        self.created_datasets_overview.overview_table.param.watch(self.update_dataset_overview, \"selection\")        \n",
    "        \n",
    "        self.gui = pn.Tabs((\"Dataset Filter\", self.dataset_filter_with_export), (\"Dataset Overview\", self.datasets_overview))\n",
    "        \n",
    "    def create_export_gui(self):\n",
    "        self.export_path = pnw.TextInput(name=\"Export path\", value=\"datasets\", height=50)\n",
    "        self.export_button = pnw.Button(name=\"Export\", align=\"end\", height=50)\n",
    "        self.export_button.on_click(self.export_datasets)\n",
    "        \n",
    "        export_dataset_name = \"\" if len(self.created_datasets) == 0 else self.created_datasets[self.export_dataset_overview.selection[0]].name\n",
    "        export_description_name = \"\" if len(self.created_datasets) == 0 else self.created_datasets[self.export_dataset_overview.selection[0]].description\n",
    "        self.export_name_input = pnw.TextInput(name=\"Dataset name\", value=export_dataset_name, height=50)\n",
    "        self.export_name_input.param.watch(self.change_dataset_name, \"value\")\n",
    "        self.export_description_input = pnw.TextAreaInput(name=\"Description\", value=export_description_name, height=50)\n",
    "        self.export_description_input.param.watch(self.change_dataset_description, \"value\")\n",
    "        return pn.Column(pn.Row(self.export_name_input, self.export_description_input), pn.Row(self.export_path, self.export_button))\n",
    "        \n",
    "    def change_dataset_name(self, event):\n",
    "        index = self.created_datasets_overview.overview_table.selection[0]\n",
    "        self.created_datasets[index].name = self.export_name_input.value\n",
    "    \n",
    "    def change_dataset_description(self, event):\n",
    "        index = self.created_datasets_overview.overview_table.selection[0]\n",
    "        self.created_datasets[index].description = self.export_description_input.value\n",
    "        \n",
    "    def update_dataset_overview(self, event):\n",
    "        self.selected_dataset_overview = self.DATASET_OVERVIEW(self.created_datasets[event.new[0]], height=self.height-350)\n",
    "        self.datasets_overview[1] = self.selected_dataset_overview.show()\n",
    "        self.export_name_input.value = self.created_datasets[event.new[0]].name\n",
    "        self.export_description_input.value = self.created_datasets[event.new[0]].description\n",
    "        \n",
    "    def create_dataset(self, clicks):\n",
    "        mask = self.dataset_filter.get_selection()\n",
    "        new_sub_dataset = self.base_dataset.create_new_from_mask(self.base_dataset, mask)\n",
    "        self.created_datasets.append(new_sub_dataset)\n",
    "\n",
    "    def export_datasets(self, clicks):\n",
    "        export_path = self.export_path.value\n",
    "        if not os.path.isdir(export_path):\n",
    "            os.makedirs(export_path)\n",
    "        for dataset in self.created_datasets:\n",
    "            dataset.save(export_path)\n",
    "        \n",
    "    def show(self):\n",
    "        return self.gui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is required to have to following (default) `descriptors`:\n",
    "\n",
    "- **data** [pd.Datagrame]: Each row represents a datapoint\n",
    "- **stats** [pd.Datagrame]: One row that descripbes the dataset, were the columns represent different information\n",
    "\n",
    "Furthermore, the dataset set if required to have the following `functions`:\n",
    "\n",
    "- **create_new_from_mask(class_instance, mask)**: Class function that is called with a mask and an instance of the class, that returns a new instance\n",
    "- **save(save_path)**: Can be called with a path and save the dataset to that path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generator = DatasetGenerator(test_dataset, height=700, width=500)\n",
    "dataset_generator.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
